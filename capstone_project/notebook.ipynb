{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4451cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import requests\n",
    "import urllib\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.preprocessing.image import load_img, ImageDataGenerator\n",
    "from tensorflow import keras\n",
    "import tensorflow.lite as tflite\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcec830",
   "metadata": {},
   "source": [
    "dataset is taken from https://www.kaggle.com/alxmamaev/flowers-recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c610c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/flowers/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48e0e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (150, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31361b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img(f'{path}daisy/100080576_f52e8ee070_n.jpg', target_size=target_size)\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd34e59a",
   "metadata": {},
   "source": [
    "# Split data in test, train, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caf17fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_types = ['daisy', 'rose', 'tulip', 'dandelion', 'sunflower']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8656ff06",
   "metadata": {},
   "outputs": [],
   "source": [
    "for flower_type in flower_types:\n",
    "    images = os.listdir(os.path.join(path, flower_type))\n",
    "    print(f'flower: {flower_type:>10} - number images: {len(images)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de15cff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for folder in ['train', 'validation', 'test']:\n",
    "    for flower_type in flower_types:\n",
    "        directory = os.path.join(path, folder, flower_type)\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "            print(f'created dir {directory}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ed6e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.15\n",
    "val_size = 0.15\n",
    "\n",
    "for flower_type in flower_types:\n",
    "    flower_type_path = os.path.join(path, flower_type)\n",
    "    images = os.listdir(flower_type_path)\n",
    "    \n",
    "    total_num_images = len(images)\n",
    "    random.seed(1)\n",
    "    random.shuffle(images)\n",
    "    \n",
    "    num_test_images = int(total_num_images*test_size)\n",
    "    num_val_images = int(total_num_images*val_size)\n",
    "    num_train_images = total_num_images - num_test_images - num_val_images\n",
    "    \n",
    "    for i in range(num_test_images):\n",
    "        img = images.pop()\n",
    "        image_path = os.path.join(flower_type_path, img)\n",
    "        shutil.copyfile(image_path, f'{path}/test/{flower_type}/{img}')\n",
    "        \n",
    "    for i in range(num_val_images):\n",
    "        img = images.pop()\n",
    "        image_path = os.path.join(flower_type_path, img)\n",
    "        shutil.copyfile(image_path, f'{path}/validation/{flower_type}/{img}')\n",
    "        \n",
    "    for i in range(len(images)):\n",
    "        img = images.pop()\n",
    "        image_path = os.path.join(flower_type_path, img)\n",
    "        shutil.copyfile(image_path, f'{path}/train/{flower_type}/{img}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d1cd75",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2e7d4a",
   "metadata": {},
   "source": [
    "## check imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44687a8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "flower_dict = {}\n",
    "for flower_type in flower_types:\n",
    "    flower_dict[flower_type] = {}\n",
    "    for folder in ['test', 'train', 'validation']:\n",
    "        flower_path = os.path.join(path, folder, flower_type)\n",
    "        if os.path.isdir(flower_path):\n",
    "            images = os.listdir(flower_path)\n",
    "            flower_dict[flower_type][folder] = len(images)\n",
    "            print(f'flower: {flower_type:>10} - {folder} - number images: {len(images)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddea2e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(flower_types, [flower_dict[flower]['train'] for flower in flower_types], width=.5)\n",
    "plt.title('training data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806b465c",
   "metadata": {},
   "source": [
    "the data set seems to be balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4565fc1e",
   "metadata": {},
   "source": [
    "## investigate image sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7406f330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dims(img_path):\n",
    "    img = Image.open(img_path)\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    arr = np.array(img, dtype='float32')\n",
    "    h, w, d = arr.shape\n",
    "    return h, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7991b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_dict = {}\n",
    "for flower_type in flower_types:\n",
    "    size_dict[flower_type] = []\n",
    "    for folder in ['test', 'train', 'validation']:\n",
    "        flower_path = os.path.join(path, folder, flower_type)\n",
    "        if os.path.isdir(flower_path):\n",
    "            images = os.listdir(flower_path)\n",
    "            for image in images:\n",
    "                h, w = get_dims(f'{flower_path}/{image}')\n",
    "                size_dict[flower_type].append({'hight': h, 'width': w})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603b3abf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for flower in flower_types:\n",
    "    hights = [pic['hight'] for pic in size_dict[flower]]\n",
    "    widths = [pic['width'] for pic in size_dict[flower]]\n",
    "    plt.scatter(widths, hights)\n",
    "    plt.xlabel('width')\n",
    "    plt.ylabel('hights')\n",
    "    plt.title(f'{flower} pic sizes (pixels)')\n",
    "    plt.pause(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae19f38",
   "metadata": {},
   "source": [
    "size distribution between the different flower types seems similar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d30a6e0",
   "metadata": {},
   "source": [
    "## show random images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b3f5ea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for flower_type in flower_types:\n",
    "    for folder in ['test', 'train', 'validation']:\n",
    "        flower_path = os.path.join(path, folder, flower_type)\n",
    "        if os.path.isdir(flower_path):\n",
    "            print(flower_path)\n",
    "            images = os.listdir(flower_path)\n",
    "            random.seed(1)\n",
    "            random.shuffle(images)\n",
    "            f, axarr = plt.subplots(1, 4, figsize=(10, 20))\n",
    "            for i, img in enumerate(images[:4]):\n",
    "                axarr[i].imshow(load_img(f'{flower_path}/{img}', target_size=target_size))\n",
    "                axarr[i].axis('off')\n",
    "            plt.pause(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2df6f90",
   "metadata": {},
   "source": [
    "almost all images look good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99485144",
   "metadata": {},
   "source": [
    "# linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8da9e6f",
   "metadata": {},
   "source": [
    "# start with easy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79f4b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    inputs = keras.Input(shape=(target_size[0], target_size[1], 3))\n",
    "    conv = keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(inputs)\n",
    "    pooling = keras.layers.MaxPool2D(strides=(2, 2))(conv)\n",
    "    flatten = keras.layers.Flatten()(pooling)\n",
    "    dense = keras.layers.Dense(64, activation='relu')(flatten)\n",
    "    outputs = keras.layers.Dense(len(flower_types), activation='softmax')(dense)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "\n",
    "    optimizer = keras.optimizers.SGD(lr=0.002, momentum=0.8)\n",
    "    loss = keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91069122",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_model = make_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61ee099",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data = train_generator.flow_from_directory(\n",
    "    f'{path}train/',\n",
    "    target_size=target_size,\n",
    "    batch_size=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4de7cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "val_data = val_generator.flow_from_directory(\n",
    "    f'{path}validation',\n",
    "    target_size=target_size,\n",
    "    batch_size=20,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3bd601",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.class_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faff012",
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_types_pred_dict = {v:k for k, v in train_data.class_indices.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c74348",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = initial_model.fit(\n",
    "    train_data,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=10,\n",
    "    validation_data=val_data,\n",
    "    validation_steps=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d71bec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fde2bc",
   "metadata": {},
   "source": [
    "# parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30942eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(conv_layers=1, learning_rate=3e-3, dropout_rate=0.2):\n",
    "    inputs = keras.Input(shape=(target_size[0], target_size[1], 3))\n",
    "    \n",
    "    conv = keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(inputs)\n",
    "    pooling = keras.layers.MaxPool2D(strides=(2, 2))(conv)\n",
    "    \n",
    "    for layer in range(conv_layers):\n",
    "        conv = keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(pooling)\n",
    "        pooling = keras.layers.MaxPool2D(strides=(2, 2))(conv)\n",
    "    \n",
    "    \n",
    "    flatten = keras.layers.Flatten()(pooling)\n",
    "    dropout = keras.layers.Dropout(rate=dropout_rate)(flatten)\n",
    "    dense = keras.layers.Dense(64, activation='relu')(dropout)\n",
    "    outputs = keras.layers.Dense(len(flower_types), activation='softmax')(dense)\n",
    "    \n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "\n",
    "    optimizer = keras.optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999)\n",
    "    loss = keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f272c73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chechpoint = keras.callbacks.ModelCheckpoint(\n",
    "'flower_model_{epoch:02d}_{val_accuracy:.3f}.h5',\n",
    "save_best_only=True,\n",
    "monitor='val_accuracy',\n",
    "mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa4cb47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bfee8a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_data,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=10,\n",
    "    validation_data=val_data,\n",
    "    validation_steps=10,\n",
    "    callbacks=[chechpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f931861",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08f847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "for lr in [0.0001, 0.001, 0.01]:\n",
    "    print(lr)\n",
    "    m = build_model(learning_rate=lr)\n",
    "    history = m.fit(\n",
    "    train_data,\n",
    "    steps_per_epoch=80,\n",
    "    epochs=8,\n",
    "    validation_data=val_data,\n",
    "    validation_steps=10,\n",
    "    callbacks=[chechpoint])\n",
    "    scores[lr] = history.history\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cd6c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr, hist in scores.items():\n",
    "    plt.plot(hist['val_accuracy'], label=('val=%s' % lr))\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f46b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "for dr in [0.1, 0.2]:\n",
    "    print(dr)\n",
    "    m = build_model(dropout_rate=dr)\n",
    "    history = m.fit(\n",
    "    train_data,\n",
    "    steps_per_epoch=80,\n",
    "    epochs=8,\n",
    "    validation_data=val_data,\n",
    "    validation_steps=10,\n",
    "    callbacks=[chechpoint])\n",
    "    scores[dr] = history.history\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0244ff8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dr, hist in scores.items():\n",
    "    plt.plot(hist['val_accuracy'], label=('val=%s' % dr))\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c42496",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "for layer in [1, 2]:\n",
    "    print(layer)\n",
    "    m = build_model(conv_layers=layer)\n",
    "    history = m.fit(\n",
    "    train_data,\n",
    "    steps_per_epoch=80,\n",
    "    epochs=8,\n",
    "    validation_data=val_data,\n",
    "    validation_steps=10,\n",
    "    callbacks=[chechpoint])\n",
    "    scores[layer] = history.history\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9d8b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer, hist in scores.items():\n",
    "    plt.plot(hist['val_accuracy'], label=('val=%s' % layer))\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ace36f",
   "metadata": {},
   "source": [
    "# use test set to check the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2437e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_data = test_generator.flow_from_directory(\n",
    "    f'{path}test',\n",
    "    target_size=target_size,\n",
    "    batch_size=20,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4be77e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_test = model.predict_generator(test_data)\n",
    "predicted_class_indices_test = np.argmax(pred_test,axis=1)\n",
    "predictions = [flower_types_pred_dict[p] for p in predicted_class_indices_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc615c7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix([flower_types_pred_dict[p] for p in predicted_class_indices_test], \n",
    "                 [flower_types_pred_dict[l] for l in test_data.labels], \n",
    "                 labels=list(flower_types_pred_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9429e792",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'accuracy: {sum(predicted_class_indices_test == test_data.labels) / len(predicted_class_indices_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f43861",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax, linewidths=0.1)\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels')\n",
    "ax.set_title('Confusion Matrix')\n",
    "ax.xaxis.set_ticklabels(list(flower_types_pred_dict.values()))\n",
    "ax.yaxis.set_ticklabels(list(flower_types_pred_dict.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4126d443",
   "metadata": {},
   "source": [
    "# save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7922d7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../models/flowers-model-v1.tflite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a5b824",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tflite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(model_path, 'wb') as f_out:\n",
    "    f_out.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd697a7",
   "metadata": {},
   "source": [
    "# make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27d1fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tflite.Interpreter(model_path=model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_index = interpreter.get_input_details()[0]['index']\n",
    "output_index = interpreter.get_output_details()[0]['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ac8e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image(img_path, target_size):\n",
    "    with open(img_path, 'rb') as file:\n",
    "        img = file.read()\n",
    "        stream = BytesIO(img)\n",
    "        img = Image.open(stream)\n",
    "    \n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img = img.resize(target_size, Image.NEAREST)\n",
    "    \n",
    "    x = np.array(img, dtype='float32')\n",
    "    X = np.array([x])\n",
    "    X /= 255.0\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7140e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = f'{path}test/rose/1461381091_aaaa663bbe_n.jpg'\n",
    "load_img(test_image, target_size=target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bec5bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = prepare_image(test_image, target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aec3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_index, X)\n",
    "interpreter.invoke()\n",
    "preds = interpreter.get_tensor(output_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7f1382",
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_types_pred_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e0ef10",
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_types_pred_dict[preds.argmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21bd492",
   "metadata": {},
   "source": [
    "# test local API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4a5daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(url):\n",
    "    with urllib.request.urlopen(url) as resp:\n",
    "        buffer = resp.read()\n",
    "    stream = BytesIO(buffer)\n",
    "    img = Image.open(stream)\n",
    "    return img\n",
    "\n",
    "def resize_image(image, target_size):\n",
    "    if image.mode != 'RGB':\n",
    "        image = image.convert('RGB')\n",
    "    image = image.resize(target_size, Image.NEAREST)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d28746",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_urls = [\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/c/cc/Hundsrose.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/a/a8/Tulipa_cinnabarina_subsp_cinnabarina.png',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/8/85/Tulipa_praestans1.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/e/ea/Tulipa_suaveolens_floriade_to_Canberra.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/e/eb/Wild_Rosa_gallica_Romania.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/0/0c/Rosa_Ave_Maria_1.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/f/f7/2010_sonnenblume_%28Helianthus_annuus%29.JPG',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/e/e9/Sonsbeck_-_agri_06_ies.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/d/d6/Taraxacum_officinale_focused.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/8/85/01_pusteblume.jpg',\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/5/5a/Bellis_perennis-fully_bloomed_flower.jpg'    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a3a676",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for url in image_urls:\n",
    "    print(url)\n",
    "    img = download_image(url)\n",
    "    img = resize_image(img, target_size)\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37241673",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://192.168.178.36:9696/predict'\n",
    "image_url = 'https://upload.wikimedia.org/wikipedia/commons/a/a8/Tulipa_cinnabarina_subsp_cinnabarina.png'\n",
    "\n",
    "print(image_url)\n",
    "img = download_image(image_url)\n",
    "img = resize_image(img, target_size)\n",
    "display(img)\n",
    "flower_pic_url = {'url': image_url}\n",
    "resp = requests.post(url, json=flower_pic_url).json()\n",
    "print(resp)\n",
    "print(f\"It is a {resp['flower']}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecced87",
   "metadata": {},
   "source": [
    "# test Heroku APP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95edf9d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url = 'https://flower-types.herokuapp.com/predict'\n",
    "flower_pic_url = {'url': 'https://upload.wikimedia.org/wikipedia/commons/c/cc/Hundsrose.jpg'}\n",
    "\n",
    "requests.post(url, json=flower_pic_url).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4dcd3e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for image_url in image_urls:\n",
    "    print(image_url)\n",
    "    img = download_image(image_url)\n",
    "    img = resize_image(img, target_size)\n",
    "    display(img)\n",
    "    flower_pic_url = {'url': image_url}\n",
    "    resp = requests.post(url, json=flower_pic_url).json()\n",
    "    print(resp)\n",
    "    print(f\"It is a {resp['flower']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa93476a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zoomcamp",
   "language": "python",
   "name": "zoomcamp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
